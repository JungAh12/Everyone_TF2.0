{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TF2.0_tensor.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JungAh12/Everyone_TF2.0/blob/master/TF2_0_tensor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "njJZ1BQbgNzu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "774d7da8-c79a-4705-aec3-ee1ee5a3a09e"
      },
      "source": [
        "!pip install -q tensorflow-gpu==2.0.0-rc1"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 380.5MB 43kB/s \n",
            "\u001b[K     |████████████████████████████████| 4.3MB 37.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 501kB 57.1MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8X4P95TgbpE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dL79bWuGgdLL",
        "colab_type": "text"
      },
      "source": [
        "#tensor\n",
        "텐서는 넘파이의 ndarray와 비슷하다.\n",
        "\n",
        "`tf.Tensor`는 GPU, TPU같은 가속기 메모리에 상주할 수 있다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZkEg6NztgsM4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "79938d1e-4492-41c4-a1df-879b21115a57"
      },
      "source": [
        "print(tf.add(1,2))  #1+2\n",
        "print(tf.add([1,2],[3,4]))  #[1+3, 2+4]\n",
        "print(tf.square(5)) #5**2\n",
        "print(tf.reduce_sum([1,2,3])) #1+2+3"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(3, shape=(), dtype=int32)\n",
            "tf.Tensor([4 6], shape=(2,), dtype=int32)\n",
            "tf.Tensor(25, shape=(), dtype=int32)\n",
            "tf.Tensor(6, shape=(), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hSaagfQg--X",
        "colab_type": "text"
      },
      "source": [
        "각 텐서는 크기(shape)와 데이터 타입(dtype)을 가지고 있다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ybe_On8phHd9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "8764fc0a-7ca2-4b61-8bf3-ac1c131abf93"
      },
      "source": [
        "x = tf.matmul([[1]],[[2,3]])\n",
        "print(x)\n",
        "print(x.shape)\n",
        "print(x.dtype)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor([[2 3]], shape=(1, 2), dtype=int32)\n",
            "(1, 2)\n",
            "<dtype: 'int32'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IEKl5_5ShMx_",
        "colab_type": "text"
      },
      "source": [
        "#Numpy의 배열과 tf.Tensor의 차이\n",
        "1. 텐서는 가속기 메모리에서 사용가능하다.\n",
        "2. 텐서는 불변성을 갖는다.\n",
        "\n",
        "#Numpy와의 호환\n",
        "tensorflow는 자동으로 numpy array를 tensor로 변환한다.\n",
        "\n",
        "numpy는 자동으로 tensor를 numpy array로 변환한다.\n",
        "\n",
        "`.numpy()`를 사용해서 넘파이 배열로 변환할 수 있다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VxxsTJswhZ0j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "21fa2d34-58e2-4ab8-a07a-99560c835dc5"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "ndarray = np.ones([3, 3]) # 1로 채워진 3x3 matrix\n",
        "\n",
        "print(\"tf 연산은 자동으로 numpy array를 tensor로 변환한다.\")\n",
        "tensor = tf.multiply(ndarray, 42) #ndarray 각 요소에 42 곱함\n",
        "print(tensor)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf 연산은 자동으로 numpy array를 tensor로 변환한다.\n",
            "tf.Tensor(\n",
            "[[42. 42. 42.]\n",
            " [42. 42. 42.]\n",
            " [42. 42. 42.]], shape=(3, 3), dtype=float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ov2rXR7SiC9E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "b3fc1cfa-e502-4a9c-a7d2-0da87ae4879a"
      },
      "source": [
        "print(\"numpy 연산은 자동으로 tensor를 numpy array로 변환한다.\")\n",
        "print(np.add(tensor, 1))    #tensor 각 요소에 1 더함"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "numpy 연산은 자동으로 tensor를 numpy array로 변환한다.\n",
            "[[43. 43. 43.]\n",
            " [43. 43. 43.]\n",
            " [43. 43. 43.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KADLGkoriVD1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "b823f4e6-b67b-4960-ce71-8b131815b69e"
      },
      "source": [
        "print(\".numpy()는 텐서를 넘파이배열로 변환한다.\")\n",
        "print(tensor.numpy())"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".numpy()는 텐서를 넘파이배열로 변환한다.\n",
            "[[42. 42. 42.]\n",
            " [42. 42. 42.]\n",
            " [42. 42. 42.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19n0Zxj6ianp",
        "colab_type": "text"
      },
      "source": [
        "#GPU사용하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8MM30CUihd1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "2d7a40cf-e6b9-401f-b0ae-8e500cacdf8f"
      },
      "source": [
        "x = tf.random.uniform([3,3]) #uniform distribution(균등분포)에 따라 랜덤으로 값을 추출하여 3x3 Tensor 생성\n",
        "\n",
        "print(\"is gpu available\"),\n",
        "print(tf.test.is_gpu_available())\n",
        "\n",
        "print(\"텐서가 GPU #0에 있는가\")\n",
        "print(x.device.endswith('GPU:0'))\n",
        "\n",
        "## Colab에서는 하드웨어 세팅 변경해줘야함."
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "is gpu available\n",
            "True\n",
            "텐서가 GPU #0에 있는가\n",
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGxk1V3bjCvz",
        "colab_type": "text"
      },
      "source": [
        "#장치 이름\n",
        "`Tensor.device`는 텐서를 구성하는 호스트 장치의 풀네임을 제공한다.\n",
        "\n",
        "텐서가 호스트의 N번째 GPU에 놓여지면 문자열은 GPU:N으로 나온다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PGcHTvxhjzun",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "17c21a08-3728-400f-f081-edef54ad1205"
      },
      "source": [
        "x.device"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/job:localhost/replica:0/task:0/device:GPU:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hq8PBlRAj4aG",
        "colab_type": "text"
      },
      "source": [
        "#명시적 장치 배치\n",
        "`tf.device`를 사용해서 특정 장치에 텐서를 배치할 수 있다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2N415YrAkCB2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "3b95981b-a759-4415-c278-5d559823d1ff"
      },
      "source": [
        "import time\n",
        "\n",
        "def time_matmul(x):\n",
        "    start = time.time()\n",
        "    for loop in range(10):\n",
        "        tf.matmul(x, x)\n",
        "    \n",
        "    result = time.time()-start\n",
        "    print(\"10 loops: {:0.2f}ms\".format(1000*result))\n",
        "\n",
        "#CPU 실행\n",
        "print(\"On CPU:\")\n",
        "with tf.device(\"CPU:0\"):\n",
        "    x = tf.random.uniform([1000,1000])  #1000x1000 tensor\n",
        "    assert x.device.endswith(\"CPU:0\")\n",
        "    time_matmul(x)\n",
        "\n",
        "#GPU 사용가능하면 GPU#0에서 강제 실행한다.\n",
        "if tf.test.is_gpu_available():\n",
        "    print(\"On GPU:\")\n",
        "    with tf.device(\"GPU:0\"):\n",
        "        x = tf.random.uniform([1000,1000])\n",
        "        assert x.device.endswith(\"GPU:0\")\n",
        "        time_matmul(x)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "On CPU:\n",
            "10 loops: 320.58ms\n",
            "On GPU:\n",
            "10 loops: 1235.42ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZSEs0UbbkvyA",
        "colab_type": "text"
      },
      "source": [
        "GPU가 더 오래 걸리는 이유는 아마 host(cpu)->device(gpu)로 복사할때 PCIe bus 속도가 느리기 때문일 것이다.\n",
        "\n",
        "#Dataset\n",
        "`tf.data.Dataset` API를 사용해서 파이프라인을 구축하자.\n",
        "\n",
        "위 API는 모델을 training, evaluation loop를 제공할, 간단하고 재사용 가능한 모듈로부터 복잡한 입력 파이프라인을 구축하기 위해 사용된다.\n",
        "\n",
        "#source dataset 생성하기\n",
        "`Dataset.from_tensors, Dataset.from_tensor_slices`와 같은 팩토리 함수 중 하나를 사용하거나 파일로부터 읽어들이는 객체인 `TextLineDataset, TFRecordDataset`을 사용해서 소스 데이터셋을 생성할 수 있다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Er-bycQ5lK0Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ds_tensors = tf.data.Dataset.from_tensor_slices([1,2,3,4,5,6])\n",
        "\n",
        "#CSV file 생성\n",
        "import tempfile\n",
        "_, filename = tempfile.mkstemp()\n",
        "\n",
        "with open(filename, 'w') as f:\n",
        "    f.write(\"\"\"Line1\n",
        "    Line2\n",
        "    Line3\n",
        "    \"\"\")\n",
        "\n",
        "ds_file = tf.data.TextLineDataset(filename)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3U4TwH4vmTMW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ds_tensors = ds_tensors.map(tf.square).shuffle(2).batch(2) #map(tf.square) = 각 요소 제곱, shuffle(2) = buffer에 2개 담아서 버퍼로부터 무작위 샘플링, batch(2) = 2개씩 배치로 묶음\n",
        "\n",
        "ds_file = ds_file.batch(2)  #2개씩 배치로 묶음"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9-1JQJzmUAs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "87a8ea7b-9a38-4448-8ae5-94528405ecce"
      },
      "source": [
        "print('ds_tensors elements:')\n",
        "for x in ds_tensors:\n",
        "    print(x)\n",
        "\n",
        "print('\\nds_file elements:')\n",
        "for x in ds_file:\n",
        "    print(x)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ds_tensors elements:\n",
            "tf.Tensor([4 1], shape=(2,), dtype=int32)\n",
            "tf.Tensor([ 9 25], shape=(2,), dtype=int32)\n",
            "tf.Tensor([36 16], shape=(2,), dtype=int32)\n",
            "\n",
            "ds_file elements:\n",
            "tf.Tensor([b'Line1' b'    Line2'], shape=(2,), dtype=string)\n",
            "tf.Tensor([b'    Line3' b'    '], shape=(2,), dtype=string)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zyh7rbQZmk1V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}